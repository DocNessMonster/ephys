{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec4cd730-ccf3-4771-82c5-7014c609cd6a",
   "metadata": {},
   "source": [
    "This code is for analyzing CSV files created by FIBSI. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852c7555-d2b4-4e2b-a3ae-c689217e13d0",
   "metadata": {},
   "source": [
    "Import packages needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568f25a0-ef7d-4928-9e80-a353fd097636",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np  # Import numpy for NaN handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9178c847-5169-48d4-9fb9-5406c3d50ee7",
   "metadata": {},
   "source": [
    "The following code calculates if a file has DSFs and the frequency of DSFs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83b7701-1d17-4a82-a80d-43f4e5c54809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where CSV files are located\n",
    "directory = \"HS23_DSFs_rest\"\n",
    "\n",
    "# Initialize lists to store data\n",
    "filenames = []\n",
    "dsf_percentages = []\n",
    "counts_zero = []\n",
    "\n",
    "# Iterate through files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        \n",
    "        # Initialize DSF% to 0 and count of '0' values to 0 for the current file\n",
    "        dsf_percentage = 0\n",
    "        count_zero = 0\n",
    "        \n",
    "        # Read the CSV file\n",
    "        try:\n",
    "            df = pd.read_csv(filepath)\n",
    "            \n",
    "            # Count '0' values in 'indicator' column\n",
    "            count_zero = df[df['indicator'] == 0]['indicator'].count()\n",
    "            \n",
    "            # Determine DSF% based on count of '0' values\n",
    "            if count_zero > 0:\n",
    "                dsf_percentage = 1\n",
    "            \n",
    "        except pd.errors.EmptyDataError:\n",
    "            # Handle empty file (no data)\n",
    "            pass\n",
    "        \n",
    "        # Append data to lists\n",
    "        filenames.append(filename)\n",
    "        dsf_percentages.append(dsf_percentage)\n",
    "        counts_zero.append(count_zero)\n",
    "\n",
    "# Create a DataFrame\n",
    "df_results = pd.DataFrame({\n",
    "    'File': filenames,\n",
    "    'DSF%': dsf_percentages,\n",
    "    'Count of 0': counts_zero\n",
    "})\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7452545f-de92-4679-ae09-c14da10290a7",
   "metadata": {},
   "source": [
    "Save as CSV file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4670686-abdb-4cf0-a3ab-e730a92a127e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "output_csv = \"HS23_DSF_count.csv\"\n",
    "df_results.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"Results saved to {output_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cd1dd5-c87e-4f3a-80c8-4a790c555302",
   "metadata": {},
   "source": [
    "This code calculates DSF amplitudes and puts the results in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069095df-1310-4eee-9c2f-29dd68184609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where CSV files are located\n",
    "directory = \"HS23_DSFs_rest\"\n",
    "\n",
    "# Initialize a dictionary to store original amplitudes\n",
    "original_amplitudes_dict = {}\n",
    "\n",
    "# Initialize a list to track maximum length of 'original amplitude' lists\n",
    "max_length = 0\n",
    "\n",
    "# Iterate through files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        \n",
    "        # Initialize DSF% to 0 and count of '0' values to 0 for the current file\n",
    "        dsf_percentage = 0\n",
    "        count_zero = 0\n",
    "        original_amplitudes = []\n",
    "        \n",
    "        # Read the CSV file\n",
    "        try:\n",
    "            df = pd.read_csv(filepath)\n",
    "            \n",
    "            # Count '0' values in 'indicator' column\n",
    "            count_zero = df[df['indicator'] == 0]['indicator'].count()\n",
    "            \n",
    "            # Extract 'original amplitude' values where 'indicator' is '0'\n",
    "            original_amplitudes = df.loc[df['indicator'] == 0, 'original amplitude'].tolist()\n",
    "            \n",
    "            # Determine DSF% based on count of '0' values\n",
    "            if count_zero > 0:\n",
    "                dsf_percentage = 1\n",
    "            \n",
    "            # Store original amplitudes in dictionary with filename as key\n",
    "            original_amplitudes_dict[filename] = original_amplitudes\n",
    "            \n",
    "            # Update max_length if current list length is greater\n",
    "            max_length = max(max_length, len(original_amplitudes))\n",
    "        \n",
    "        except pd.errors.EmptyDataError:\n",
    "            # Handle empty file (no data)\n",
    "            original_amplitudes_dict[filename] = []\n",
    "\n",
    "# Fill in missing values with NaN to ensure all lists are of the same length\n",
    "for filename, amps in original_amplitudes_dict.items():\n",
    "    if len(amps) < max_length:\n",
    "        original_amplitudes_dict[filename].extend([np.nan] * (max_length - len(amps)))\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "df_original_amplitudes = pd.DataFrame(original_amplitudes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9ffa2b-4b34-465c-aff1-480e6e6346d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "output_csv = \"HS23_DSF_amplitudes.csv\"\n",
    "df_original_amplitudes.to_csv(output_csv, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be06d1a4-ef4c-4236-af7a-3c34d1248f54",
   "metadata": {},
   "source": [
    "This code calculates DSF durations and puts them into a dataframe. and saves a CSV file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05297fb-36dc-4188-a745-87e506bb6a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where CSV files are located\n",
    "directory = \"HS23_DSFs_rest\"\n",
    "\n",
    "# Initialize a dictionary to store event durations\n",
    "event_durations_dict = {}\n",
    "\n",
    "# Initialize a variable to track the maximum length of event duration lists\n",
    "max_length = 0\n",
    "\n",
    "# Iterate through files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        \n",
    "        # Initialize event durations list for the current file\n",
    "        event_durations = []\n",
    "        \n",
    "        # Read the CSV file\n",
    "        try:\n",
    "            df = pd.read_csv(filepath)\n",
    "            \n",
    "            # Filter rows where 'indicator' is '0'\n",
    "            df_filtered = df[df['indicator'] == 0]\n",
    "            \n",
    "            # Calculate event durations\n",
    "            durations = (pd.to_datetime(df_filtered['end time']) - pd.to_datetime(df_filtered['start time'])).dt.total_seconds()\n",
    "            event_durations = durations.tolist()\n",
    "            \n",
    "            # Store event durations in dictionary with filename as key\n",
    "            event_durations_dict[filename] = event_durations\n",
    "            \n",
    "            # Update max_length if current list length is greater\n",
    "            max_length = max(max_length, len(event_durations))\n",
    "        \n",
    "        except pd.errors.EmptyDataError:\n",
    "            # Handle empty file (no data)\n",
    "            event_durations_dict[filename] = []\n",
    "\n",
    "# Fill in missing values with NaN to ensure all lists are of the same length\n",
    "for filename, durations in event_durations_dict.items():\n",
    "    if len(durations) < max_length:\n",
    "        event_durations_dict[filename].extend([np.nan] * (max_length - len(durations)))\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "df_event_durations = pd.DataFrame(event_durations_dict)\n",
    "\n",
    "# Save the DataFrame to a new CSV file\n",
    "df_event_durations.to_csv('HS23_DSF_durations.csv', index=False)\n",
    "\n",
    "print(\"Event durations have been calculated and saved successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
